{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## AzureML Model Monitoring through Operationalization"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this sample notebook, you will observe the end-to-end lifecycle of the Machine Learning (ML) operationalization process. You will follow the following steps to train your ML model, deploy it to production, and monitor it to ensure its continuous performance:\n",
        "\n",
        "1) Setup environment \n",
        "2) Register data assets\n",
        "3) Train the model\n",
        "4) Deploy the model\n",
        "5) Simulate inference requests\n",
        "6) Monitor the model\n",
        "\n",
        "Let's begin. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup your environment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "To start, connect to your project workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# Connect to the project workspace\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\nClass DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1769698228274
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up a compute cluster to use to train your model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "cluster_basic = AmlCompute(\n",
        "    name=\"cpu-cluster\",\n",
        "    type=\"amlcompute\",\n",
        "    size=\"STANDARD_F2S_V2\",  # you can replace it with other supported VM SKUs\n",
        "    location=ml_client.workspaces.get(ml_client.workspace_name).location,\n",
        "    min_instances=0,\n",
        "    max_instances=1,\n",
        "    idle_time_before_scale_down=360,\n",
        ")\n",
        "\n",
        "ml_client.begin_create_or_update(cluster_basic).result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/__init__.py:41: UserWarning: Versions of mlflow (3.8.1) and child packages mlflow-skinny (3.5.0) are different. This may lead to unexpected behavior. Please install the same version of all MLflow packages.\n  mlflow.mismatch._check_version_mismatch()\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "AmlCompute({'type': 'amlcompute', 'created_on': None, 'provisioning_state': 'Succeeded', 'provisioning_errors': None, 'name': 'cpu-cluster', 'description': None, 'tags': None, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/2e5fc10d-039e-4cb2-975d-4ed7bc31a0ee/resourceGroups/datacollecrg/providers/Microsoft.MachineLearningServices/workspaces/amlforuaicaroljan/computes/cpu-cluster', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/carsilva3/code/Users/carsilva/amle2emonitoring/notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x78f28ffed5d0>, 'resource_id': None, 'location': 'westeurope', 'size': 'STANDARD_F2S_V2', 'min_instances': 0, 'max_instances': 1, 'idle_time_before_scale_down': 360.0, 'identity': None, 'ssh_public_access_enabled': True, 'ssh_settings': None, 'network_settings': <azure.ai.ml.entities._compute.compute.NetworkSettings object at 0x78f28ffedb70>, 'tier': 'dedicated', 'enable_node_public_ip': True, 'subnet': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1769691502917
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register data assets"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's use some sample data to train our model. We will randomly split the dataset into reference and production sets. We add a timestamp column to simulate \"production-like\" data, since production data typically comes with timestamps. The dataset we are using in this example notebook has several columns related to credit card borrowers and contains a column on whether or not they defaulted on their credit card debt. We will train a model to predict `DEFAULT_NEXT_MONTH`, which is whether or not a borrower will default on their debt next month."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "# Read the default_of_credit_card_clients dataset into a pandas data frame\n",
        "data_path = \"https://azuremlexamples.blob.core.windows.net/datasets/credit_card/default_of_credit_card_clients.csv\"\n",
        "df = pd.read_csv(data_path, header=1, index_col=0).rename(\n",
        "    columns={\"default payment next month\": \"DEFAULT_NEXT_MONTH\"}\n",
        ")\n",
        "\n",
        "# Split the data into production_data_df and reference_data_df\n",
        "# Use the iloc method to select the first 80% and the last 20% of the rows\n",
        "reference_data_df = df.iloc[: int(0.8 * len(df))].copy()\n",
        "production_data_df = df.iloc[int(0.8 * len(df)) :].copy()\n",
        "\n",
        "# Add a timestamp column in ISO8601 format\n",
        "timestamp = datetime.datetime.now() - datetime.timedelta(days=45)\n",
        "reference_data_df[\"TIMESTAMP\"] = timestamp.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
        "production_data_df[\"TIMESTAMP\"] = [\n",
        "    timestamp + datetime.timedelta(minutes=i * 10)\n",
        "    for i in range(len(production_data_df))\n",
        "]\n",
        "production_data_df[\"TIMESTAMP\"] = production_data_df[\"TIMESTAMP\"].apply(\n",
        "    lambda x: x.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1769691504456
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "def write_df(df, local_path, file_name):\n",
        "    # Create directory if it does not exist\n",
        "    os.makedirs(local_path, exist_ok=True)\n",
        "\n",
        "    # Write data\n",
        "    df.to_csv(f\"{local_path}/{file_name}\", index=False)\n",
        "\n",
        "\n",
        "# Write data to local directory\n",
        "reference_data_dir_local_path = \"../data/reference\"\n",
        "production_data_dir_local_path = \"../data/production\"\n",
        "\n",
        "write_df(reference_data_df, reference_data_dir_local_path, \"01.csv\"),\n",
        "write_df(production_data_df, production_data_dir_local_path, \"01.csv\")"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1769691505456
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mltable\n",
        "from mltable import MLTableHeaders, MLTableFileEncoding\n",
        "\n",
        "from azureml.fsspec import AzureMachineLearningFileSystem\n",
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "\n",
        "def upload_data_and_create_data_asset(\n",
        "    local_path, remote_path, datastore_uri, data_name, data_version\n",
        "):\n",
        "    # Write MLTable file\n",
        "    tbl = mltable.from_delimited_files(\n",
        "        paths=[{\"pattern\": f\"{datastore_uri}{remote_path}*.csv\"}],\n",
        "        delimiter=\",\",\n",
        "        header=\"all_files_same_headers\",\n",
        "        infer_column_types=True,\n",
        "        include_path_column=False,\n",
        "        encoding=\"utf8\",\n",
        "    )\n",
        "\n",
        "    tbl.save(local_path)\n",
        "\n",
        "    # Instantiate file system\n",
        "    fs = AzureMachineLearningFileSystem(datastore_uri)\n",
        "\n",
        "    # Upload data\n",
        "    fs.upload(\n",
        "        lpath=local_path,\n",
        "        rpath=remote_path,\n",
        "        recursive=False,\n",
        "        **{\"overwrite\": \"MERGE_WITH_OVERWRITE\"},\n",
        "    )\n",
        "\n",
        "    # Define the Data asset object\n",
        "    data = Data(\n",
        "        path=f\"{datastore_uri}{remote_path}\",\n",
        "        type=AssetTypes.MLTABLE,\n",
        "        name=data_name,\n",
        "        version=data_version,\n",
        "    )\n",
        "\n",
        "    # Create the data asset in the workspace\n",
        "    ml_client.data.create_or_update(data)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "# Datastore uri for data\n",
        "datastore_uri = \"azureml://subscriptions/{}/resourcegroups/{}/workspaces/{}/datastores/workspaceblobstore/paths/\".format(\n",
        "    ml_client.subscription_id, ml_client.resource_group_name, ml_client.workspace_name\n",
        ")\n",
        "\n",
        "# Define paths\n",
        "reference_data_dir_remote_path = \"data/credit-default/reference/\"\n",
        "production_data_dir_remote_path = \"data/credit-default/production/\"\n",
        "\n",
        "# Define data asset names\n",
        "reference_data_asset_name = \"credit-default-reference1\"\n",
        "production_data_asset_name = \"credit-default-production1\"\n",
        "\n",
        "# Write data to remote directory and create data asset\n",
        "reference_data = upload_data_and_create_data_asset(\n",
        "    reference_data_dir_local_path,\n",
        "    reference_data_dir_remote_path,\n",
        "    datastore_uri,\n",
        "    reference_data_asset_name,\n",
        "    \"1\",\n",
        ")\n",
        "production_data = upload_data_and_create_data_asset(\n",
        "    production_data_dir_local_path,\n",
        "    production_data_dir_remote_path,\n",
        "    datastore_uri,\n",
        "    production_data_asset_name,\n",
        "    \"1\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1769692387766
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_job\n",
        "\n",
        "# Define training pipeline directory\n",
        "training_pipeline_path = \"../configurations/training_pipeline.yaml\"\n",
        "\n",
        "# Trigger training\n",
        "training_pipeline_definition = load_job(source=training_pipeline_path)\n",
        "training_pipeline_job = ml_client.jobs.create_or_update(training_pipeline_definition)\n",
        "\n",
        "ml_client.jobs.stream(training_pipeline_job.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.MLFlowModelJobOutput'> and will be ignored\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: placid_eye_r1vlmf4c4h\nWeb View: https://ml.azure.com/runs/placid_eye_r1vlmf4c4h?wsid=/subscriptions/2e5fc10d-039e-4cb2-975d-4ed7bc31a0ee/resourcegroups/datacollecrg/workspaces/amlforuaicaroljan\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2026-01-29 14:53:54Z] Submitting 1 runs, first five are: 994d1139:6b098789-bde3-425b-bd98-44b7a2bacb01\n[2026-01-29 14:59:53Z] Completing processing run id 6b098789-bde3-425b-bd98-44b7a2bacb01.\n\nExecution Summary\n=================\nRunId: placid_eye_r1vlmf4c4h\nWeb View: https://ml.azure.com/runs/placid_eye_r1vlmf4c4h?wsid=/subscriptions/2e5fc10d-039e-4cb2-975d-4ed7bc31a0ee/resourcegroups/datacollecrg/workspaces/amlforuaicaroljan\n\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1769698811441
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy the model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deploy the model with AzureML managed online endpoints."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Endpoint"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_online_endpoint\n",
        "\n",
        "# Define endpoint directory\n",
        "endpoint_path = \"../endpoints/endpoint.yaml\"\n",
        "\n",
        "# Trigger endpoint creation\n",
        "endpoint_definition = load_online_endpoint(source=endpoint_path)\n",
        "endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint_definition)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1769698986169
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check endpoint status\n",
        "endpoint = ml_client.online_endpoints.get(name=endpoint_definition.name)\n",
        "print(\n",
        "    f'Endpoint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved'\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpoint \"credit-default-carol\" with provisioning state \"Succeeded\" is retrieved\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1769699051843
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Deployment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "As part of the deployment configuration, the Model Data Collector (MDC) is enabled, so that inference data is collected for model monitoring. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_online_deployment\n",
        "\n",
        "# Define deployment directory\n",
        "deployment_path = \"../endpoints/deployment.yaml\"\n",
        "\n",
        "# Trigger deployment creation\n",
        "deployment_definition = load_online_deployment(source=deployment_path)\n",
        "deployment = ml_client.online_deployments.begin_create_or_update(deployment_definition)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint credit-default-carol exists\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ".."
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1769699252457
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check deployment status\n",
        "deployment = ml_client.online_deployments.get(\n",
        "    name=deployment_definition.name, endpoint_name=endpoint_definition.name\n",
        ")\n",
        "print(\n",
        "    f'Deployment \"{deployment.name}\" with provisioning state \"{deployment.provisioning_state}\" is retrieved'\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Deployment \"main\" with provisioning state \"Creating\" is retrieved\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1769699258041
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "terminal_states = {\"Succeeded\", \"Failed\", \"Canceled\"}\n",
        "success_state = \"Succeeded\"\n",
        "\n",
        "while True:\n",
        "    deployment = ml_client.online_deployments.get(\n",
        "        name=deployment_definition.name,\n",
        "        endpoint_name=endpoint_definition.name,\n",
        "    )\n",
        "\n",
        "    state = deployment.provisioning_state\n",
        "    print(f'Deployment \"{deployment.name}\" provisioning state: \"{state}\"')\n",
        "\n",
        "    if state == success_state:\n",
        "        print(\"✅ Deployment is ready (Succeeded).\")\n",
        "        break\n",
        "\n",
        "    if state in terminal_states and state != success_state:\n",
        "        raise RuntimeError(f\"❌ Deployment ended in terminal state: {state}\")\n",
        "  \n",
        "\n",
        "    # Not done yet (e.g., Creating/Updating)\n",
        "    time.sleep(15)\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n..Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\nDeployment \"main\" provisioning state: \"Creating\"\n..Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n..Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n...Deployment \"main\" provisioning state: \"Creating\"\n..Deployment \"main\" provisioning state: \"Succeeded\"\n✅ Deployment is ready (Succeeded).\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1769700219903
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = ml_client.online_endpoints.get(endpoint_definition.name)\n",
        "\n",
        "endpoint.traffic = {\n",
        "    \"main\": 100\n",
        "}\n",
        "\n",
        "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "\n",
        "print(\"✅ 100% traffic assigned to deployment 'main'\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Readonly attribute principal_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\nReadonly attribute tenant_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ 100% traffic assigned to deployment 'main'\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1769700312016
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulate production inference data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Sample Data\n",
        "\n",
        "We generate sample inference data by taking the distribution for each input feature and adding a small amount of random noise. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define numeric and categotical feature columns\n",
        "NUMERIC_FEATURES = [\n",
        "    \"LIMIT_BAL\",\n",
        "    \"AGE\",\n",
        "    \"BILL_AMT1\",\n",
        "    \"BILL_AMT2\",\n",
        "    \"BILL_AMT3\",\n",
        "    \"BILL_AMT4\",\n",
        "    \"BILL_AMT5\",\n",
        "    \"BILL_AMT6\",\n",
        "    \"PAY_AMT1\",\n",
        "    \"PAY_AMT2\",\n",
        "    \"PAY_AMT3\",\n",
        "    \"PAY_AMT4\",\n",
        "    \"PAY_AMT5\",\n",
        "    \"PAY_AMT6\",\n",
        "]\n",
        "CATEGORICAL_FEATURES = [\n",
        "    \"SEX\",\n",
        "    \"EDUCATION\",\n",
        "    \"MARRIAGE\",\n",
        "    \"PAY_0\",\n",
        "    \"PAY_2\",\n",
        "    \"PAY_3\",\n",
        "    \"PAY_4\",\n",
        "    \"PAY_5\",\n",
        "    \"PAY_6\",\n",
        "]\n",
        "\n",
        "\n",
        "def generate_sample_inference_data(df_production, number_of_records=20):\n",
        "    # Sample records\n",
        "    df_sample = df_production.sample(n=number_of_records, replace=True)\n",
        "\n",
        "    # Generate numeric features with random noise\n",
        "    df_numeric_generated = pd.DataFrame(\n",
        "        {\n",
        "            feature: np.random.normal(\n",
        "                0, df_production[feature].std(), number_of_records\n",
        "            ).astype(np.int64)\n",
        "            for feature in NUMERIC_FEATURES\n",
        "        }\n",
        "    ) + df_sample[NUMERIC_FEATURES].reset_index(drop=True)\n",
        "\n",
        "    # Take categorical columns\n",
        "    df_categorical = df_sample[CATEGORICAL_FEATURES].reset_index(drop=True)\n",
        "\n",
        "    # Combine numerical and categorical columns\n",
        "    df_combined = pd.concat([df_numeric_generated, df_categorical], axis=1)\n",
        "\n",
        "    return df_combined"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1769700312242
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mltable\n",
        "import pandas as pd\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# Load production / inference data\n",
        "data_asset = ml_client.data.get(\"credit-default-production\", version=\"1\")\n",
        "tbl = mltable.load(data_asset.path)\n",
        "df_production = tbl.to_pandas_dataframe()\n",
        "\n",
        "# Generate sample data for inference\n",
        "number_of_records = 20\n",
        "df_generated = generate_sample_inference_data(df_production, number_of_records)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Overriding of current TracerProvider is not allowed\nOverriding of current LoggerProvider is not allowed\nOverriding of current MeterProvider is not allowed\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nOverriding of current TracerProvider is not allowed\nOverriding of current LoggerProvider is not allowed\nOverriding of current MeterProvider is not allowed\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Resolving access token for scope \"https://storage.azure.com/.default\" using identity of type \"MANAGED\".\nGetting data access token with Assigned Identity (client_id=clientid) and endpoint type based on configuration\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1769700319508
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_generated)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "    LIMIT_BAL  AGE  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n0      203493   54     131565     -13817      65222     158942      -9961   \n1      142592   32      41289    -178963      57650    -186662      19470   \n2     -104267   31     -28690      64921      68486     -11122     -24126   \n3       91286   35     150656      93909      39057     131161      99607   \n4      372679   32      45727     277585     151244     199390    -125193   \n5      174515   24    -103854      -8155     -61038     -28022     -35993   \n6     -223198   43     -42713      51426     -37248    -125736      81092   \n7      231280   12     335322     286797     215197     358969     244640   \n8      224819   32      14906    -123993     -85802      47576      55653   \n9       13920   38     -18873     245384     -57942     -89002      10082   \n10     110749   13     -40629       9569     126364      -6779     131651   \n11     -89290   22     -14399     -22850     -39470     -19593       4659   \n12      71519   16     214276      85562     158017      96549      86060   \n13     393884   29      68002     125318     -45465     -32966      39242   \n14      77584    8     132909      47625     114201      -4212      81110   \n15    -142169   61     120160      82634      74490      97320     -23300   \n16     -88942   24      84446     273692     119160      59885      83115   \n17     -53904   28      67044      28643      23741      65278      38239   \n18      49372   33      81799      72474     -36889      85513     -20509   \n19     157686   37     -79653      26040      52628      92647      90509   \n\n    BILL_AMT6  PAY_AMT1  PAY_AMT2  ...  PAY_AMT6  SEX  EDUCATION  MARRIAGE  \\\n0       86276    -37007    -25423  ...      6245    2          3         2   \n1      -38633      6185     -1179  ...    -38357    2          1         2   \n2       52045      5154     17808  ...     -8172    1          1         2   \n3       32120     25268     46858  ...      2988    2          2         1   \n4      -14051     17269     21504  ...      8982    2          2         1   \n5      -31037    -41914     47313  ...    -13062    2          2         2   \n6       79448      5976     13112  ...      7124    1          2         1   \n7      248936     65647    -21467  ...     11081    1          1         1   \n8      -29147    -11242    -19837  ...     26350    2          3         1   \n9      114926     17564     25501  ...     21440    2          2         2   \n10     134125     12012    -17362  ...    -29100    1          1         2   \n11      82699     12440     16052  ...     -3413    2          2         1   \n12       6279      5001      7568  ...     -9138    1          2         2   \n13     172290      6278     32228  ...     18392    2          3         2   \n14      55286     32716     17096  ...     44330    2          2         2   \n15     135826     42944    -23392  ...      3463    1          3         1   \n16      69685      9852      3112  ...     18487    2          1         2   \n17      32579      4124    -18409  ...     14923    1          2         1   \n18      22526     34643    -14304  ...    -17886    2          2         3   \n19     145172     19434    -35260  ...     14239    2          1         2   \n\n    PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  PAY_6  \n0       0      0      0      2      0      0  \n1       1     -2     -2     -2     -1      2  \n2       1      2      0      0     -2     -2  \n3       0      0      0      0      0      0  \n4       0      0      0      0      0      0  \n5      -2     -2     -2     -2     -2     -2  \n6       0      0      0      0      0      2  \n7       0      0      0      0      0      0  \n8      -2     -2     -2     -2     -2     -2  \n9       1      2      0      0      0      0  \n10      0      0      2      0      0      0  \n11      0      0      0      0      0      0  \n12      0      0      0      0      0      0  \n13     -1     -1     -2     -2     -2     -2  \n14      3      2      2      2      2      2  \n15      0      0      0      0      0      0  \n16      2      0      0      0      0      0  \n17      0      0      0      0      0      0  \n18      0      0      0      0      0      0  \n19     -2     -2     -2     -2     -2     -2  \n\n[20 rows x 23 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LIMIT_BAL</th>\n      <th>AGE</th>\n      <th>BILL_AMT1</th>\n      <th>BILL_AMT2</th>\n      <th>BILL_AMT3</th>\n      <th>BILL_AMT4</th>\n      <th>BILL_AMT5</th>\n      <th>BILL_AMT6</th>\n      <th>PAY_AMT1</th>\n      <th>PAY_AMT2</th>\n      <th>...</th>\n      <th>PAY_AMT6</th>\n      <th>SEX</th>\n      <th>EDUCATION</th>\n      <th>MARRIAGE</th>\n      <th>PAY_0</th>\n      <th>PAY_2</th>\n      <th>PAY_3</th>\n      <th>PAY_4</th>\n      <th>PAY_5</th>\n      <th>PAY_6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>203493</td>\n      <td>54</td>\n      <td>131565</td>\n      <td>-13817</td>\n      <td>65222</td>\n      <td>158942</td>\n      <td>-9961</td>\n      <td>86276</td>\n      <td>-37007</td>\n      <td>-25423</td>\n      <td>...</td>\n      <td>6245</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>142592</td>\n      <td>32</td>\n      <td>41289</td>\n      <td>-178963</td>\n      <td>57650</td>\n      <td>-186662</td>\n      <td>19470</td>\n      <td>-38633</td>\n      <td>6185</td>\n      <td>-1179</td>\n      <td>...</td>\n      <td>-38357</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-104267</td>\n      <td>31</td>\n      <td>-28690</td>\n      <td>64921</td>\n      <td>68486</td>\n      <td>-11122</td>\n      <td>-24126</td>\n      <td>52045</td>\n      <td>5154</td>\n      <td>17808</td>\n      <td>...</td>\n      <td>-8172</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-2</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>91286</td>\n      <td>35</td>\n      <td>150656</td>\n      <td>93909</td>\n      <td>39057</td>\n      <td>131161</td>\n      <td>99607</td>\n      <td>32120</td>\n      <td>25268</td>\n      <td>46858</td>\n      <td>...</td>\n      <td>2988</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>372679</td>\n      <td>32</td>\n      <td>45727</td>\n      <td>277585</td>\n      <td>151244</td>\n      <td>199390</td>\n      <td>-125193</td>\n      <td>-14051</td>\n      <td>17269</td>\n      <td>21504</td>\n      <td>...</td>\n      <td>8982</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>174515</td>\n      <td>24</td>\n      <td>-103854</td>\n      <td>-8155</td>\n      <td>-61038</td>\n      <td>-28022</td>\n      <td>-35993</td>\n      <td>-31037</td>\n      <td>-41914</td>\n      <td>47313</td>\n      <td>...</td>\n      <td>-13062</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-223198</td>\n      <td>43</td>\n      <td>-42713</td>\n      <td>51426</td>\n      <td>-37248</td>\n      <td>-125736</td>\n      <td>81092</td>\n      <td>79448</td>\n      <td>5976</td>\n      <td>13112</td>\n      <td>...</td>\n      <td>7124</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>231280</td>\n      <td>12</td>\n      <td>335322</td>\n      <td>286797</td>\n      <td>215197</td>\n      <td>358969</td>\n      <td>244640</td>\n      <td>248936</td>\n      <td>65647</td>\n      <td>-21467</td>\n      <td>...</td>\n      <td>11081</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>224819</td>\n      <td>32</td>\n      <td>14906</td>\n      <td>-123993</td>\n      <td>-85802</td>\n      <td>47576</td>\n      <td>55653</td>\n      <td>-29147</td>\n      <td>-11242</td>\n      <td>-19837</td>\n      <td>...</td>\n      <td>26350</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>13920</td>\n      <td>38</td>\n      <td>-18873</td>\n      <td>245384</td>\n      <td>-57942</td>\n      <td>-89002</td>\n      <td>10082</td>\n      <td>114926</td>\n      <td>17564</td>\n      <td>25501</td>\n      <td>...</td>\n      <td>21440</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>110749</td>\n      <td>13</td>\n      <td>-40629</td>\n      <td>9569</td>\n      <td>126364</td>\n      <td>-6779</td>\n      <td>131651</td>\n      <td>134125</td>\n      <td>12012</td>\n      <td>-17362</td>\n      <td>...</td>\n      <td>-29100</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>-89290</td>\n      <td>22</td>\n      <td>-14399</td>\n      <td>-22850</td>\n      <td>-39470</td>\n      <td>-19593</td>\n      <td>4659</td>\n      <td>82699</td>\n      <td>12440</td>\n      <td>16052</td>\n      <td>...</td>\n      <td>-3413</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>71519</td>\n      <td>16</td>\n      <td>214276</td>\n      <td>85562</td>\n      <td>158017</td>\n      <td>96549</td>\n      <td>86060</td>\n      <td>6279</td>\n      <td>5001</td>\n      <td>7568</td>\n      <td>...</td>\n      <td>-9138</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>393884</td>\n      <td>29</td>\n      <td>68002</td>\n      <td>125318</td>\n      <td>-45465</td>\n      <td>-32966</td>\n      <td>39242</td>\n      <td>172290</td>\n      <td>6278</td>\n      <td>32228</td>\n      <td>...</td>\n      <td>18392</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>77584</td>\n      <td>8</td>\n      <td>132909</td>\n      <td>47625</td>\n      <td>114201</td>\n      <td>-4212</td>\n      <td>81110</td>\n      <td>55286</td>\n      <td>32716</td>\n      <td>17096</td>\n      <td>...</td>\n      <td>44330</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>-142169</td>\n      <td>61</td>\n      <td>120160</td>\n      <td>82634</td>\n      <td>74490</td>\n      <td>97320</td>\n      <td>-23300</td>\n      <td>135826</td>\n      <td>42944</td>\n      <td>-23392</td>\n      <td>...</td>\n      <td>3463</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>-88942</td>\n      <td>24</td>\n      <td>84446</td>\n      <td>273692</td>\n      <td>119160</td>\n      <td>59885</td>\n      <td>83115</td>\n      <td>69685</td>\n      <td>9852</td>\n      <td>3112</td>\n      <td>...</td>\n      <td>18487</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>-53904</td>\n      <td>28</td>\n      <td>67044</td>\n      <td>28643</td>\n      <td>23741</td>\n      <td>65278</td>\n      <td>38239</td>\n      <td>32579</td>\n      <td>4124</td>\n      <td>-18409</td>\n      <td>...</td>\n      <td>14923</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>49372</td>\n      <td>33</td>\n      <td>81799</td>\n      <td>72474</td>\n      <td>-36889</td>\n      <td>85513</td>\n      <td>-20509</td>\n      <td>22526</td>\n      <td>34643</td>\n      <td>-14304</td>\n      <td>...</td>\n      <td>-17886</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>157686</td>\n      <td>37</td>\n      <td>-79653</td>\n      <td>26040</td>\n      <td>52628</td>\n      <td>92647</td>\n      <td>90509</td>\n      <td>145172</td>\n      <td>19434</td>\n      <td>-35260</td>\n      <td>...</td>\n      <td>14239</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows × 23 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1769700319744
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Call Online Managed Endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the endpoint with the sample data. Since your deployment was created with the Model Data Collector (MDC) enabled, the inference inputs and outputs will be collected in your workspace blob storage. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "request_file_name = \"request.json\"\n",
        "\n",
        "# Request sample data\n",
        "data = {\"data\": df_generated.to_dict(orient=\"records\")}\n",
        "\n",
        "# Write sample data\n",
        "with open(request_file_name, \"w\") as f:\n",
        "    json.dump(data, f)\n",
        "\n",
        "# Call online endpoint\n",
        "result = ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=endpoint_definition.name,\n",
        "    deployment_name=deployment_definition.name,\n",
        "    request_file=request_file_name,\n",
        ")\n",
        "\n",
        "# Delete sample data\n",
        "os.remove(request_file_name)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1769700320560
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\"{\\\"DEFAULT_NEXT_MONTH\\\": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false]}\"\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1769700320837
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install -U azureml-fsspec==1.3.1 pandas\n",
        "\n",
        "import pandas as pd\n",
        "from azureml.fsspec import AzureMachineLearningFileSystem\n",
        "\n",
        "def browse_and_preview(uri, max_list=100):\n",
        "    fs = AzureMachineLearningFileSystem(uri)\n",
        "\n",
        "    items = fs.find(\"/\")  # recursive\n",
        "    print(f\"\\nURI: {uri}\")\n",
        "    print(f\"Found {len(items)} items\")\n",
        "    for p in items[:max_list]:\n",
        "        print(\"  \", p)\n",
        "\n",
        "    # preview first parquet/csv/jsonl found\n",
        "    candidates = [p for p in items if p.lower().endswith((\".parquet\",\".csv\",\".jsonl\"))]\n",
        "    if not candidates:\n",
        "        print(\"No parquet/csv/jsonl files found to preview.\")\n",
        "        return\n",
        "\n",
        "    sample = candidates[0]\n",
        "    print(\"\\nPreviewing:\", sample)\n",
        "\n",
        "    if sample.lower().endswith(\".parquet\"):\n",
        "        df = pd.read_parquet(fs.open(sample))\n",
        "        print(df.head(10))\n",
        "    elif sample.lower().endswith(\".csv\"):\n",
        "        df = pd.read_csv(fs.open(sample))\n",
        "        print(df.head(10))\n",
        "    else:  # jsonl\n",
        "        import json\n",
        "        rows = []\n",
        "        with fs.open(sample) as f:\n",
        "            for _ in range(20):\n",
        "                rows.append(json.loads(next(f)))\n",
        "        df = pd.DataFrame(rows)\n",
        "        print(df.head(10))\n",
        "\n",
        "# ---- Example URIs (replace endpoint/deployment with yours) ----\n",
        "endpoint = endpoint_definition.name\n",
        "deployment = deployment_definition.name\n",
        "\n",
        "# base = f\"azureml://datastores/workspaceblobstore/paths/modelDataCollector/{endpoint}/{deployment}\"\n",
        "#azureml://subscriptions/80ef7369-572a-4abd-b09a-033367f44858/resourcegroups/amltest1/workspaces/amltest1/datastores/workspaceblobstore/paths/modelDataCollector/credit-default-bb26/main/model_outputs/\n",
        "#base = f\"azureml://subscriptions/80ef7369-572a-4abd-b09a-033367f44858/resourcegroups/amltest1/workspaces/amltest1/datastores/workspaceblobstore/paths/modelDataCollector/credit-default-bb26/main\"\n",
        "base = f\"azureml://subscriptions/2e5fc10d-039e-4cb2-975d-4ed7bc31a0ee/resourcegroups/datacollecRG/workspaces/amlforuaicaroljan/datastores/workspaceblobstore/paths/modelDataCollector/{endpoint}/{deployment}\"\n",
        "print(base)\n",
        "\n",
        "browse_and_preview(f\"{base}/model_inputs/\")\n",
        "\n",
        "#browse_and_preview(f\"{base}/inputs_outputs\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "azureml://subscriptions/2e5fc10d-039e-4cb2-975d-4ed7bc31a0ee/resourcegroups/datacollecRG/workspaces/amlforuaicaroljan/datastores/workspaceblobstore/paths/modelDataCollector/credit-default-carol/main\n\nURI: azureml://subscriptions/2e5fc10d-039e-4cb2-975d-4ed7bc31a0ee/resourcegroups/datacollecRG/workspaces/amlforuaicaroljan/datastores/workspaceblobstore/paths/modelDataCollector/credit-default-carol/main/model_inputs/\nFound 78 items\n   LocalUpload/5314df52c81210d5668eca591f1f6dbe5da1a319b66eabc5fb1b3d45eb5672bf/model/MLmodel\n   LocalUpload/5314df52c81210d5668eca591f1f6dbe5da1a319b66eabc5fb1b3d45eb5672bf/model/conda.yaml\n   LocalUpload/5314df52c81210d5668eca591f1f6dbe5da1a319b66eabc5fb1b3d45eb5672bf/model/model.pkl\n   LocalUpload/5314df52c81210d5668eca591f1f6dbe5da1a319b66eabc5fb1b3d45eb5672bf/model/requirements.txt\n   LocalUpload/8e7865a95e00bc0123a7fbcdf675009ff120748629ee957b5bb71ee967f99d7a/model/MLmodel\n   LocalUpload/8e7865a95e00bc0123a7fbcdf675009ff120748629ee957b5bb71ee967f99d7a/model/conda.yaml\n   LocalUpload/8e7865a95e00bc0123a7fbcdf675009ff120748629ee957b5bb71ee967f99d7a/model/model.pkl\n   LocalUpload/8e7865a95e00bc0123a7fbcdf675009ff120748629ee957b5bb71ee967f99d7a/model/requirements.txt\n   UI/2026-01-28_144355_UTC/pilots.frontend.csv\n   WebUpload/260113143836-2358389181/model.joblib\n   WebUpload/260113144107-1091568474/model.joblib\n   WebUpload/260113144249-2713200398/model.joblib\n   WebUpload/260114092701-77371591/model/MLmodel.txt\n   WebUpload/260114092701-77371591/model/conda.yaml\n   WebUpload/260114092701-77371591/model/model.pkl\n   WebUpload/260114092701-77371591/model/python_env.yaml\n   WebUpload/260114092701-77371591/model/requirements.txt\n   WebUpload/260128133854-2489844995/mlflow_model/MLmodel\n   WebUpload/260128133854-2489844995/mlflow_model/conda.yaml\n   WebUpload/260128133854-2489844995/mlflow_model/model.pkl\n   WebUpload/260128133854-2489844995/mlflow_model/python_env.yaml\n   WebUpload/260128133854-2489844995/mlflow_model/requirements.txt\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/_tracer.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/_tracing.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/_vendor_jwt_decode.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/azureml_globals.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/context_managers.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/job_prep.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/log_history_status.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/request_utilities.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/run_token_provider.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/utility_context_managers.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82.zip\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/_tracer.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/_tracing.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/_vendor_jwt_decode.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/azureml_globals.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/context_managers.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/job_prep.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/log_history_status.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/request_utilities.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/run_token_provider.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/utility_context_managers.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709.zip\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/_tracer.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/_tracing.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/_vendor_jwt_decode.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/azureml_globals.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/context_managers.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/job_prep.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/log_history_status.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/request_utilities.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/run_token_provider.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/utility_context_managers.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01.zip\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01/model_output/MLmodel\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01/model_output/conda.yaml\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01/model_output/model.pkl\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01/model_output/python_env.yaml\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01/model_output/requirements.txt\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/_tracer.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/_tracing.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/_vendor_jwt_decode.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/azureml_globals.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/context_managers.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/job_prep.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/log_history_status.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/request_utilities.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/run_token_provider.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/utility_context_managers.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0.zip\n   data/credit-default/production/01.csv\n   data/credit-default/production/MLTable\n   data/credit-default/reference/01.csv\n   data/credit-default/reference/MLTable\n   modelDataCollector/credit-default-carol/main/model_inputs/2026/01/29/15/259b69d8a1fe41f29f77c607e4172f0a000000.jsonl\n   modelDataCollector/credit-default-carol/main/model_inputs_outputs/2026/01/29/15/259b69d8a1fe41f29f77c607e4172f0a000000.jsonl\n   modelDataCollector/credit-default-carol/main/model_outputs/2026/01/29/15/259b69d8a1fe41f29f77c607e4172f0a000000.jsonl\n\nPreviewing: UI/2026-01-28_144355_UTC/pilots.frontend.csv\n           character          ship_name\n0           Han Solo  Millennium Falcon\n1     Luke Skywalker             X-Wing\n2        Darth Vader        TIE Fighter\n3          Boba Fett            Slave I\n4        Leia Organa   Imperial Shuttle\n5   Lando Calrissian  Millennium Falcon\n6     Wedge Antilles             X-Wing\n7  Emperor Palpatine           Executor\n8          Chewbacca  Millennium Falcon\n9             Ackbar     Star Destroyer\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Overriding of current TracerProvider is not allowed\nOverriding of current LoggerProvider is not allowed\nOverriding of current MeterProvider is not allowed\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nOverriding of current TracerProvider is not allowed\nOverriding of current LoggerProvider is not allowed\nOverriding of current MeterProvider is not allowed\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1769700412598
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "browse_and_preview(f\"{base}/model_outputs/\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nURI: azureml://subscriptions/2e5fc10d-039e-4cb2-975d-4ed7bc31a0ee/resourcegroups/datacollecRG/workspaces/amlforuaicaroljan/datastores/workspaceblobstore/paths/modelDataCollector/credit-default-carol/main/model_outputs/\nFound 78 items\n   LocalUpload/5314df52c81210d5668eca591f1f6dbe5da1a319b66eabc5fb1b3d45eb5672bf/model/MLmodel\n   LocalUpload/5314df52c81210d5668eca591f1f6dbe5da1a319b66eabc5fb1b3d45eb5672bf/model/conda.yaml\n   LocalUpload/5314df52c81210d5668eca591f1f6dbe5da1a319b66eabc5fb1b3d45eb5672bf/model/model.pkl\n   LocalUpload/5314df52c81210d5668eca591f1f6dbe5da1a319b66eabc5fb1b3d45eb5672bf/model/requirements.txt\n   LocalUpload/8e7865a95e00bc0123a7fbcdf675009ff120748629ee957b5bb71ee967f99d7a/model/MLmodel\n   LocalUpload/8e7865a95e00bc0123a7fbcdf675009ff120748629ee957b5bb71ee967f99d7a/model/conda.yaml\n   LocalUpload/8e7865a95e00bc0123a7fbcdf675009ff120748629ee957b5bb71ee967f99d7a/model/model.pkl\n   LocalUpload/8e7865a95e00bc0123a7fbcdf675009ff120748629ee957b5bb71ee967f99d7a/model/requirements.txt\n   UI/2026-01-28_144355_UTC/pilots.frontend.csv\n   WebUpload/260113143836-2358389181/model.joblib\n   WebUpload/260113144107-1091568474/model.joblib\n   WebUpload/260113144249-2713200398/model.joblib\n   WebUpload/260114092701-77371591/model/MLmodel.txt\n   WebUpload/260114092701-77371591/model/conda.yaml\n   WebUpload/260114092701-77371591/model/model.pkl\n   WebUpload/260114092701-77371591/model/python_env.yaml\n   WebUpload/260114092701-77371591/model/requirements.txt\n   WebUpload/260128133854-2489844995/mlflow_model/MLmodel\n   WebUpload/260128133854-2489844995/mlflow_model/conda.yaml\n   WebUpload/260128133854-2489844995/mlflow_model/model.pkl\n   WebUpload/260128133854-2489844995/mlflow_model/python_env.yaml\n   WebUpload/260128133854-2489844995/mlflow_model/requirements.txt\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/_tracer.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/_tracing.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/_vendor_jwt_decode.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/azureml_globals.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/context_managers.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/job_prep.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/log_history_status.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/request_utilities.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/run_token_provider.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82-setup/utility_context_managers.py\n   azureml/03d3fdef-9b9f-4c5d-8bf7-3a6f626dca82.zip\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/_tracer.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/_tracing.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/_vendor_jwt_decode.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/azureml_globals.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/context_managers.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/job_prep.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/log_history_status.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/request_utilities.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/run_token_provider.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709-setup/utility_context_managers.py\n   azureml/6809e2c8-051a-4bd1-b718-16bc2e1f4709.zip\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/_tracer.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/_tracing.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/_vendor_jwt_decode.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/azureml_globals.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/context_managers.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/job_prep.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/log_history_status.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/request_utilities.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/run_token_provider.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01-setup/utility_context_managers.py\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01.zip\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01/model_output/MLmodel\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01/model_output/conda.yaml\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01/model_output/model.pkl\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01/model_output/python_env.yaml\n   azureml/6b098789-bde3-425b-bd98-44b7a2bacb01/model_output/requirements.txt\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/_tracer.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/_tracing.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/_vendor_jwt_decode.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/azureml_globals.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/context_managers.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/job_prep.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/log_history_status.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/request_utilities.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/run_token_provider.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0-setup/utility_context_managers.py\n   azureml/cdbc06c5-7323-4053-868d-36a5877044e0.zip\n   data/credit-default/production/01.csv\n   data/credit-default/production/MLTable\n   data/credit-default/reference/01.csv\n   data/credit-default/reference/MLTable\n   modelDataCollector/credit-default-carol/main/model_inputs/2026/01/29/15/259b69d8a1fe41f29f77c607e4172f0a000000.jsonl\n   modelDataCollector/credit-default-carol/main/model_inputs_outputs/2026/01/29/15/259b69d8a1fe41f29f77c607e4172f0a000000.jsonl\n   modelDataCollector/credit-default-carol/main/model_outputs/2026/01/29/15/259b69d8a1fe41f29f77c607e4172f0a000000.jsonl\n\nPreviewing: UI/2026-01-28_144355_UTC/pilots.frontend.csv\n           character          ship_name\n0           Han Solo  Millennium Falcon\n1     Luke Skywalker             X-Wing\n2        Darth Vader        TIE Fighter\n3          Boba Fett            Slave I\n4        Leia Organa   Imperial Shuttle\n5   Lando Calrissian  Millennium Falcon\n6     Wedge Antilles             X-Wing\n7  Emperor Palpatine           Executor\n8          Chewbacca  Millennium Falcon\n9             Ackbar     Star Destroyer\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1769700429051
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model monitor"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import (\n",
        "    AlertNotification,\n",
        "    MonitoringTarget,\n",
        "    MonitorDefinition,\n",
        "    MonitorSchedule,\n",
        "    RecurrencePattern,\n",
        "    RecurrenceTrigger,\n",
        "    ServerlessSparkCompute,\n",
        ")\n",
        "\n",
        "# get a handle to the workspace\n",
        "# ml_client = MLClient(\n",
        "#     DefaultAzureCredential(),\n",
        "#     subscription_id=\"80ef7369-572a-4abd-b09a-033367f44858\",\n",
        "#     resource_group_name=\"amltest1\",\n",
        "#     workspace_name=\"amltest1\",\n",
        "# )\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\nOverriding of current TracerProvider is not allowed\nOverriding of current LoggerProvider is not allowed\nOverriding of current MeterProvider is not allowed\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1769700439999
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a basic model monitor. Please feel free to augment it to meet the needs of your scenario. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import (\n",
        "    AlertNotification,\n",
        "    MonitoringTarget,\n",
        "    MonitorDefinition,\n",
        "    MonitorSchedule,\n",
        "    RecurrencePattern,\n",
        "    RecurrenceTrigger,\n",
        "    ServerlessSparkCompute,\n",
        ")\n",
        "\n",
        "# get a handle to the workspace\n",
        "# ml_client = MLClient(\n",
        "#     DefaultAzureCredential(),\n",
        "#     subscription_id=\"80ef7369-572a-4abd-b09a-033367f44858\",\n",
        "#     resource_group_name=\"amltest1\",\n",
        "#     workspace_name=\"amltest1\",\n",
        "# )\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
        "\n",
        "# create the compute\n",
        "spark_compute = ServerlessSparkCompute(\n",
        "    instance_type=\"standard_e4s_v3\", runtime_version=\"3.4\"\n",
        ")\n",
        "\n",
        "# specify your online endpoint deployment\n",
        "monitoring_target = MonitoringTarget(\n",
        "    ml_task=\"classification\", endpoint_deployment_id=\"azureml:credit-default-carol:main\"\n",
        ")\n",
        "\n",
        "\n",
        "# create alert notification object\n",
        "alert_notification = AlertNotification(emails=[\"carsilva@microsoft.com\", \"carsilva@microsoft.com\"])\n",
        "\n",
        "# create the monitor definition\n",
        "monitor_definition = MonitorDefinition(\n",
        "    compute=spark_compute,\n",
        "    monitoring_target=monitoring_target,\n",
        "    alert_notification=alert_notification,\n",
        ")\n",
        "\n",
        "# specify the schedule frequency\n",
        "recurrence_trigger = RecurrenceTrigger(\n",
        "    frequency=\"day\", interval=1, schedule=RecurrencePattern(hours=3, minutes=15)\n",
        ")\n",
        "\n",
        "# create the monitor\n",
        "model_monitor = MonitorSchedule(\n",
        "    name=\"credit_default_monitor_basic\",\n",
        "    trigger=recurrence_trigger,\n",
        "    create_monitor=monitor_definition,\n",
        ")\n",
        "\n",
        "poller = ml_client.schedules.begin_create_or_update(model_monitor)\n",
        "created_monitor = poller.result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\nOverriding of current TracerProvider is not allowed\nOverriding of current LoggerProvider is not allowed\nOverriding of current MeterProvider is not allowed\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "......"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1769700531129
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is an advanced model monitoring configuration. Feel free to augment it to meet the needs of your scenario. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import Input, MLClient\n",
        "from azure.ai.ml.constants import (\n",
        "    MonitorDatasetContext,\n",
        ")\n",
        "from azure.ai.ml.entities import (\n",
        "    AlertNotification,\n",
        "    DataDriftSignal,\n",
        "    DataQualitySignal,\n",
        "    PredictionDriftSignal,\n",
        "    DataDriftMetricThreshold,\n",
        "    DataQualityMetricThreshold,\n",
        "    PredictionDriftMetricThreshold,\n",
        "    NumericalDriftMetrics,\n",
        "    CategoricalDriftMetrics,\n",
        "    DataQualityMetricsNumerical,\n",
        "    DataQualityMetricsCategorical,\n",
        "    MonitorFeatureFilter,\n",
        "    MonitoringTarget,\n",
        "    MonitorDefinition,\n",
        "    MonitorSchedule,\n",
        "    RecurrencePattern,\n",
        "    RecurrenceTrigger,\n",
        "    ServerlessSparkCompute,\n",
        "    ReferenceData,\n",
        ")\n",
        "\n",
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(),\n",
        "    subscription_id=\"2e5fc10d-039e-4cb2-975d-4ed7bc31a0ee\",\n",
        "    resource_group_name=\"datacollecRG\",\n",
        "    workspace_name=\"amlforuaicaroljan\",\n",
        ")\n",
        "\n",
        "# create your compute\n",
        "spark_compute = ServerlessSparkCompute(\n",
        "    instance_type=\"standard_e4s_v3\", runtime_version=\"3.4\"\n",
        ")\n",
        "\n",
        "# specify the online deployment (if you have one)\n",
        "monitoring_target = MonitoringTarget(\n",
        "    ml_task=\"classification\", endpoint_deployment_id=\"azureml:credit-default:main\"\n",
        ")\n",
        "\n",
        "# training data to be used as baseline dataset\n",
        "reference_data_training = ReferenceData(\n",
        "    input_data=Input(type=\"mltable\", path=\"azureml:credit-default-reference:1\"),\n",
        "    #target_column_name=\"DEFAULT_NEXT_MONTH\",\n",
        "    data_context=MonitorDatasetContext.TRAINING,\n",
        ")\n",
        "\n",
        "# create an advanced data drift signal\n",
        "features = MonitorFeatureFilter(top_n_feature_importance=10)\n",
        "\n",
        "metric_thresholds = DataDriftMetricThreshold(\n",
        "    numerical=NumericalDriftMetrics(jensen_shannon_distance=0.01),\n",
        "    categorical=CategoricalDriftMetrics(pearsons_chi_squared_test=0.02),\n",
        ")\n",
        "\n",
        "advanced_data_drift = DataDriftSignal(\n",
        "    reference_data=reference_data_training,\n",
        "    features=features,\n",
        "    metric_thresholds=metric_thresholds,\n",
        ")\n",
        "\n",
        "# create an advanced prediction drift signal\n",
        "metric_thresholds = PredictionDriftMetricThreshold(\n",
        "    categorical=CategoricalDriftMetrics(jensen_shannon_distance=0.01)\n",
        ")\n",
        "\n",
        "advanced_prediction_drift = PredictionDriftSignal(\n",
        "    reference_data=reference_data_training, metric_thresholds=metric_thresholds\n",
        ")\n",
        "\n",
        "# create an advanced data quality signal\n",
        "features = [\"SEX\", \"EDUCATION\", \"AGE\"]\n",
        "\n",
        "metric_thresholds = DataQualityMetricThreshold(\n",
        "    numerical=DataQualityMetricsNumerical(null_value_rate=0.01),\n",
        "    categorical=DataQualityMetricsCategorical(out_of_bounds_rate=0.02),\n",
        ")\n",
        "\n",
        "advanced_data_quality = DataQualitySignal(\n",
        "    reference_data=reference_data_training,\n",
        "    features=features,\n",
        "    metric_thresholds=metric_thresholds,\n",
        "    alert_enabled=False,\n",
        ")\n",
        "\n",
        "# put all monitoring signals in a dictionary\n",
        "monitoring_signals = {\n",
        "    \"data_drift_advanced\": advanced_data_drift,\n",
        "    \"data_quality_advanced\": advanced_data_quality,\n",
        "}\n",
        "\n",
        "# create alert notification object\n",
        "alert_notification = AlertNotification(emails=[\"abc@example.com\", \"def@example.com\"])\n",
        "\n",
        "# create the monitor definition\n",
        "monitor_definition = MonitorDefinition(\n",
        "    compute=spark_compute,\n",
        "    monitoring_target=monitoring_target,\n",
        "    monitoring_signals=monitoring_signals,\n",
        "    alert_notification=alert_notification,\n",
        ")\n",
        "\n",
        "# specify the frequency on which to run your monitor\n",
        "recurrence_trigger = RecurrenceTrigger(\n",
        "    frequency=\"day\", interval=1, schedule=RecurrencePattern(hours=3, minutes=15)\n",
        ")\n",
        "\n",
        "# create your monitor\n",
        "model_monitor = MonitorSchedule(\n",
        "    name=\"credit_default_monitor_advanced\",\n",
        "    trigger=recurrence_trigger,\n",
        "    create_monitor=monitor_definition,\n",
        ")\n",
        "\n",
        "poller = ml_client.schedules.begin_create_or_update(model_monitor)\n",
        "created_monitor = poller.result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Overriding of current TracerProvider is not allowed\nOverriding of current LoggerProvider is not allowed\nOverriding of current MeterProvider is not allowed\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\n"
        },
        {
          "output_type": "error",
          "ename": "ResourceNotFoundError",
          "evalue": "(ResourceNotFound) The Resource 'Microsoft.MachineLearningServices/workspaces/amlforuaicaroljan/onlineEndpoints/credit-default/deployments/main' under resource group 'datacollecRG' was not found. For more details please go to https://aka.ms/ARMResourceNotFoundFix\nCode: ResourceNotFound\nMessage: The Resource 'Microsoft.MachineLearningServices/workspaces/amlforuaicaroljan/onlineEndpoints/credit-default/deployments/main' under resource group 'datacollecRG' was not found. For more details please go to https://aka.ms/ARMResourceNotFoundFix",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceNotFoundError\u001b[0m                     Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[28], line 120\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# create your monitor\u001b[39;00m\n\u001b[1;32m    114\u001b[0m model_monitor \u001b[38;5;241m=\u001b[39m MonitorSchedule(\n\u001b[1;32m    115\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcredit_default_monitor_advanced\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m     trigger\u001b[38;5;241m=\u001b[39mrecurrence_trigger,\n\u001b[1;32m    117\u001b[0m     create_monitor\u001b[38;5;241m=\u001b[39mmonitor_definition,\n\u001b[1;32m    118\u001b[0m )\n\u001b[0;32m--> 120\u001b[0m poller \u001b[38;5;241m=\u001b[39m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedules\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_create_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_monitor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m created_monitor \u001b[38;5;241m=\u001b[39m poller\u001b[38;5;241m.\u001b[39mresult()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:138\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m span_attributes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    137\u001b[0m                 span\u001b[38;5;241m.\u001b[39madd_attribute(key, value)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Native path\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:371\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m dimensions \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameter_dimensions, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(custom_dimensions \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, dimensions) \u001b[38;5;28;01mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 371\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;66;03m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    374\u001b[0m         activityLogger\u001b[38;5;241m.\u001b[39mactivity_info\u001b[38;5;241m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_schedule_operations.py:259\u001b[0m, in \u001b[0;36mScheduleOperations.begin_create_or_update\u001b[0;34m(self, schedule, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_job_operations\u001b[38;5;241m.\u001b[39m_resolve_arm_id_or_upload_dependencies(schedule\u001b[38;5;241m.\u001b[39mcreate_job)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schedule, MonitorSchedule):\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# resolve ARM id for target, compute, and input datasets for each signal\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_monitor_schedule_arm_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschedule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# Create schedule\u001b[39;00m\n\u001b[1;32m    261\u001b[0m schedule_data \u001b[38;5;241m=\u001b[39m schedule\u001b[38;5;241m.\u001b[39m_to_rest_object()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_schedule_operations.py:345\u001b[0m, in \u001b[0;36mScheduleOperations._resolve_monitor_schedule_arm_id\u001b[0;34m(self, schedule)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mand\u001b[39;00m target\u001b[38;5;241m.\u001b[39mendpoint_deployment_id:\n\u001b[1;32m    344\u001b[0m     endpoint_name, deployment_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_and_get_endpoint_deployment_names_from_id(target)\n\u001b[0;32m--> 345\u001b[0m     online_deployment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_online_deployment_operations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     deployment_data_collector \u001b[38;5;241m=\u001b[39m online_deployment\u001b[38;5;241m.\u001b[39mdata_collector\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deployment_data_collector:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:138\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m span_attributes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    137\u001b[0m                 span\u001b[38;5;241m.\u001b[39madd_attribute(key, value)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Native path\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:288\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mstart_as_current_span(ACTIVITY_SPAN):\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[1;32m    286\u001b[0m             logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[1;32m    287\u001b[0m         ):\n\u001b[0;32m--> 288\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_logger\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_online_deployment_operations.py:239\u001b[0m, in \u001b[0;36mOnlineDeploymentOperations.get\u001b[0;34m(self, name, endpoint_name, local)\u001b[0m\n\u001b[1;32m    236\u001b[0m     deployment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_deployment_helper\u001b[38;5;241m.\u001b[39mget(endpoint_name\u001b[38;5;241m=\u001b[39mendpoint_name, deployment_name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     deployment \u001b[38;5;241m=\u001b[39m OnlineDeployment\u001b[38;5;241m.\u001b[39m_from_rest_object(\n\u001b[0;32m--> 239\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_online_deployment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m            \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresource_group_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource_group_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m            \u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workspace_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m     )\n\u001b[1;32m    248\u001b[0m deployment\u001b[38;5;241m.\u001b[39mendpoint_name \u001b[38;5;241m=\u001b[39m endpoint_name\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m deployment\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:138\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m span_attributes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    137\u001b[0m                 span\u001b[38;5;241m.\u001b[39madd_attribute(key, value)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Native path\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_online_deployments_operations.py:657\u001b[0m, in \u001b[0;36mOnlineDeploymentsOperations.get\u001b[0;34m(self, resource_group_name, workspace_name, endpoint_name, deployment_name, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m response \u001b[38;5;241m=\u001b[39m pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m]:\n\u001b[0;32m--> 657\u001b[0m     \u001b[43mmap_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize\u001b[38;5;241m.\u001b[39mfailsafe_deserialize(_models\u001b[38;5;241m.\u001b[39mErrorResponse, pipeline_response)\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, model\u001b[38;5;241m=\u001b[39merror, error_format\u001b[38;5;241m=\u001b[39mARMErrorFormat)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/exceptions.py:163\u001b[0m, in \u001b[0;36mmap_error\u001b[0;34m(status_code, response, error_map)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    162\u001b[0m error \u001b[38;5;241m=\u001b[39m error_type(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
            "\u001b[0;31mResourceNotFoundError\u001b[0m: (ResourceNotFound) The Resource 'Microsoft.MachineLearningServices/workspaces/amlforuaicaroljan/onlineEndpoints/credit-default/deployments/main' under resource group 'datacollecRG' was not found. For more details please go to https://aka.ms/ARMResourceNotFoundFix\nCode: ResourceNotFound\nMessage: The Resource 'Microsoft.MachineLearningServices/workspaces/amlforuaicaroljan/onlineEndpoints/credit-default/deployments/main' under resource group 'datacollecRG' was not found. For more details please go to https://aka.ms/ARMResourceNotFoundFix"
          ]
        }
      ],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1769701158573
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#delete the monitoring\n",
        "#delete the drift\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1769700325546
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "endpoint_name = \"credit-default-bb26\"   # <-- your endpoint name\n",
        "\n",
        "endpoint = ml_client.online_endpoints.get(endpoint_name)\n",
        "\n",
        "# Set traffic to 0 for the deployment(s) you currently route to\n",
        "# If you know the deployment name:\n",
        "endpoint.traffic = {\"main\": 0}  # replace \"blue\"\n",
        "\n",
        "ml_client.begin_create_or_update(endpoint).result()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1769700325563
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#endpoint_name = \"credit-default-bb26\"\n",
        "deployment_name = \"main\"   # <-- deployment to delete\n",
        "\n",
        "ml_client.online_deployments.begin_delete(\n",
        "    name=deployment_name,\n",
        "    endpoint_name=endpoint_name\n",
        ").result()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1769700325580
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# endpoint_name = \"credit-default-bb26\"\n",
        "\n",
        "deployments = ml_client.online_deployments.list(endpoint_name=endpoint_name)\n",
        "for d in deployments:\n",
        "    ml_client.online_deployments.begin_delete(\n",
        "        name=d.name,\n",
        "        endpoint_name=endpoint_name\n",
        "    ).result()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1769700325598
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_endpoints.begin_delete(name=endpoint_name).result()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1769700325619
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finally done"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1769700325637
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.19",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}